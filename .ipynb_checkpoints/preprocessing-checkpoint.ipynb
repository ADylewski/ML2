{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_tools as dtools\n",
    "import os \n",
    "import json\n",
    "import random\n",
    "import os \n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtools.download(dataset='Cocoa Diseases', dst_dir='~/dataset-ninja/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot = \"GoodLabels\"\n",
    "datasetPath = \"GoodImages\"\n",
    "def jsonToTxt(pathToAnnots):\n",
    "    os.makedirs(annot, exist_ok=True)\n",
    "    for n in os.listdir(pathToAnnots):\n",
    "        if not n.endswith('.json'):\n",
    "            continue\n",
    "        with open(os.path.join(pathToAnnots, n)) as json_file:\n",
    "            with open(os.path.join(annot, n[:-5] + \".txt\"), \"a\") as txt_file:\n",
    "                print(n)\n",
    "                data = json.load(json_file)\n",
    "                for nr in data[\"objects\"]:\n",
    "                    idNum = nr[\"classId\"]\n",
    "                    points = nr[\"points\"][\"exterior\"]\n",
    "                    # write txt file\n",
    "                    txt_file.write(f\"{idNum} {points[0][0]} {points[0][1]} {points[1][0]} {points[1][1]}\\n\")\n",
    "jsonToTxt(\"dataset-ninja/cocoa-diseases/all/ann/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_test_split(path,labelPath,outputPath,neg_path=None, split = 0.2):\n",
    "    print(\"------ PROCESS STARTED -------\")\n",
    "\n",
    "    #exculde files without jpg extension\n",
    "\n",
    "    files = list(set([name[:-4] for name in os.listdir(path) if name.endswith('.jpg')])) ## removing duplicate names i.e. counting only number of images\n",
    "\n",
    "    print (f\"--- This folder has a total number of {len(files)} images---\")\n",
    "    random.seed(42)\n",
    "    random.shuffle(files)\n",
    "\n",
    "    test_size = int(len(files) * split)\n",
    "    train_size = len(files) - test_size\n",
    "\n",
    "    ## creating required directories\n",
    "    train_path_img = outputPath + \"images/train/\"\n",
    "    train_path_label = outputPath + \"labels/train/\"\n",
    "    val_path_img = outputPath + \"images/val/\"\n",
    "    val_path_label = outputPath + \"labels/val/\"\n",
    "\n",
    "\n",
    "    os.makedirs(train_path_img, exist_ok = True)\n",
    "    os.makedirs(train_path_label, exist_ok = True)\n",
    "    os.makedirs(val_path_img, exist_ok = True)\n",
    "    os.makedirs(val_path_label, exist_ok = True)\n",
    "\n",
    "\n",
    "\n",
    "    ### ----------- copying images to train folder\n",
    "    for filex in files[:train_size]:\n",
    "      print(filex)\n",
    "      if filex == 'classes':\n",
    "          continue\n",
    "          \n",
    "      shutil.copy2(path + filex + '.jpg',f\"{train_path_img}/\" + filex + '.jpg' )\n",
    "      shutil.copy2(labelPath+\"/\" + filex + '.jpg'+'.txt', f\"{train_path_label}/\" + filex + '.txt')\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"------ Training data created with 80% split {len(files[:train_size])} images -------\")\n",
    "\n",
    "    if neg_path:\n",
    "        neg_images = list(set([name[:-4] for name in os.listdir(neg_path)])) ## removing duplicate names i.e. counting only number of images\n",
    "        for filex in neg_images:\n",
    "            shutil.copy2(neg_path+filex+ \".jpg\", f\"{train_path_img}/\" + filex + '.jpg')\n",
    "\n",
    "        print(f\"------ Total  {len(neg_images)} negative images added to the training data -------\")\n",
    "\n",
    "        print(f\"------ TOTAL Training data created with {len(files[:train_size]) + len(neg_images)} images -------\")\n",
    "\n",
    "\n",
    "\n",
    "    ### copytin images to validation folder\n",
    "    for filex in files[train_size:]:\n",
    "      if filex == 'classes':\n",
    "          continue\n",
    "      # print(\"running\")\n",
    "      shutil.copy2(path + filex + '.jpg', f\"{val_path_img}/\" + filex + '.jpg' )\n",
    "      shutil.copy2(labelPath+\"/\" + filex + '.jpg'+'.txt', f\"{val_path_label}/\" + filex + '.txt')\n",
    "\n",
    "    print(f\"------ Testing data created with a total of {len(files[train_size:])} images ----------\")\n",
    "\n",
    "    print(\"------ TASK COMPLETED -------\")\n",
    "\n",
    "train_test_split(\"dataset-ninja/cocoa-diseases/all/img/\",annot,datasetPath)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10",
   "language": "python",
   "name": "py3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
