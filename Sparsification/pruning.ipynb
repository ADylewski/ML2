{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68f36a09-3e6b-433d-8635-bfdc3f2a929e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cfa449-bbc5-4800-b2e6-b500426040ce",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "#### Tutorial for PyTorch pruning: https://towardsdatascience.com/how-to-prune-neural-networks-with-pytorch-ebef60316b91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5e094db-25af-4028-a554-c07277237611",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prune_model(model, amount=0.1, prune_type=\"unstructured\", dim=0):\n",
    "    \"\"\"\n",
    "    Prunes the model based on the specified prune_type.\n",
    "    \n",
    "    Args:\n",
    "        model: The model to be pruned.\n",
    "        amount: The amount of pruning to apply (e.g., fraction of weights to prune).\n",
    "        prune_type: Type of pruning: \"unstructured\" or \"structured\".\n",
    "        dim: Dimension along which to apply structured pruning (only for structured).\n",
    "    \n",
    "    Returns:\n",
    "        model: The pruned model.\n",
    "    \"\"\"\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            print(f\"Pruning module: {module}\")\n",
    "            \n",
    "            if prune_type == \"unstructured\":\n",
    "                # Apply unstructured pruning\n",
    "                prune.l1_unstructured(module, name=\"weight\", amount=amount)\n",
    "            elif prune_type == \"structured\":\n",
    "                # Apply structured pruning\n",
    "                prune.ln_structured(module, name=\"weight\", amount=amount, n=1, dim=dim)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported prune_type: {prune_type}\")\n",
    "            \n",
    "            # Remove the pruning mask and update the weights\n",
    "            prune.remove(module, \"weight\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b90eda2-cd92-4205-8d81-f686f3e4bf69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11x summary: 631 layers, 56,877,241 parameters, 0 gradients, 195.5 GFLOPs\n",
      "(631, 56877241, 0, 195.46199040000002)\n"
     ]
    }
   ],
   "source": [
    "model=YOLO(\"../cocoa_diseases_yolo11x_dense/train6/weights/best.pt\")\n",
    "print(model.info())\n",
    "torch_model=model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ced2c56-2aba-4c99-8d70-6662ed7b873d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.58 ðŸš€ Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (NVIDIA A16, 15000MiB)\n",
      "                                                       CUDA:1 (NVIDIA A16, 15000MiB)\n",
      "YOLO11x summary (fused): 464 layers, 56,830,489 parameters, 0 gradients, 194.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jovyan/ML2/datasets/cocoa_diseases/labels/val.cache... 62 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62/62 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:04<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         62        289      0.735      0.648       0.73      0.506\n",
      "          phytophthora         30         39      0.781      0.564      0.678        0.5\n",
      "               monilia         23         30      0.653      0.767      0.752       0.56\n",
      "               healthy         52        220      0.771      0.613       0.76      0.457\n",
      "Speed: 0.9ms preprocess, 67.0ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "val_dense = model.val(\n",
    "    data=\"../datasets/cocoa_diseases/cocoa_dataset.yaml\",\n",
    "    imgsz=640,\n",
    "    batch=2,  # Small batch size\n",
    "    device=[0,1]  # GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e91a9c-de70-4f43-8e8f-5f264e5a375f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Local unstructured pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79e6d7dd-4aa9-45d7-ab8a-1fae17a341a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model sparsity after pruning: 30.00%\n",
      "Model pruned.\n"
     ]
    }
   ],
   "source": [
    "pruned_torch_model=prune_model(torch_model,prune_type='unstructured', amount=0.3)\n",
    "print(\"Model pruned.\")\n",
    "model.model=pruned_torch_model\n",
    "model.save('yolo11x_trained_pruned_local_unstructured_30.pt')\n",
    "print(\"Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9ac7aa9-aac2-4c85-87ac-cb4afcb25603",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11x summary: 631 layers, 56,877,241 parameters, 0 gradients, 195.5 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(631, 56877241, 0, 195.46199040000002)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_model=YOLO('yolo11x_trained_pruned_local_unstructured_30.pt')\n",
    "sparse_model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b86bf42-db82-4781-b11b-57f0ae78514e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.58 ðŸš€ Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (NVIDIA A16, 15000MiB)\n",
      "                                                       CUDA:1 (NVIDIA A16, 15000MiB)\n",
      "YOLO11x summary (fused): 464 layers, 56,830,489 parameters, 0 gradients, 194.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jovyan/ML2/datasets/cocoa_diseases/labels/val.cache... 62 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62/62 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:05<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         62        289     0.0769      0.179     0.0393     0.0145\n",
      "          phytophthora         30         39      0.108      0.205     0.0446     0.0165\n",
      "               monilia         23         30      0.111        0.3     0.0675     0.0246\n",
      "               healthy         52        220     0.0119     0.0318    0.00563    0.00241\n",
      "Speed: 0.8ms preprocess, 62.2ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "val_sparse= sparse_model.val(\n",
    "    data=\"../datasets/cocoa_diseases/cocoa_dataset.yaml\",\n",
    "    imgsz=640,\n",
    "    batch=2,  # Small batch size\n",
    "    device=[0,1]  # GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301ab1ad-7a24-438c-98c5-dd8c1e65c2ab",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Local structured pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280592b4-9aa8-497a-af6f-f18e3756a0f5",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Channel-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92e34d31-2ea9-4d9a-b88e-c5a0fdd7f8f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11x summary: 631 layers, 56,877,241 parameters, 0 gradients, 195.5 GFLOPs\n",
      "(631, 56877241, 0, 195.46199040000002)\n",
      "Model pruned.\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "pruned_torch_model_structured=prune_model(torch_model, prune_type='structured', dim=0, amount=0.3)\n",
    "print(pruned_torch_model.info())\n",
    "print(\"Model pruned.\")\n",
    "model.model=pruned_torch_model\n",
    "model.save('yolo11x_trained_pruned_local_structured_30_channel.pt')\n",
    "print(\"Model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeb7fcd3-024e-484e-a783-62f7685e63a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.58 ðŸš€ Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (NVIDIA A16, 15000MiB)\n",
      "                                                       CUDA:1 (NVIDIA A16, 15000MiB)\n",
      "YOLO11x summary (fused): 464 layers, 56,830,489 parameters, 0 gradients, 194.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jovyan/ML2/datasets/cocoa_diseases/labels/val.cache... 62 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62/62 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:04<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         62        289   0.000436    0.00758   0.000224   6.27e-05\n",
      "          phytophthora         30         39          0          0          0          0\n",
      "               monilia         23         30          0          0          0          0\n",
      "               healthy         52        220    0.00131     0.0227   0.000671   0.000188\n",
      "Speed: 0.9ms preprocess, 60.8ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sparse_model=YOLO('yolo11x_trained_pruned_local_structured_30_channel.pt')\n",
    "val_sparse= sparse_model.val(\n",
    "    data=\"../datasets/cocoa_diseases/cocoa_dataset.yaml\",\n",
    "    imgsz=640,\n",
    "    batch=2,  # Small batch size\n",
    "    device=[0,1]  # GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a5671c-380f-4690-88da-7726b51d3ee1",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Neuron-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e0edbe0-212c-4aeb-b418-9ff9a2679729",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11x summary: 631 layers, 56,877,241 parameters, 0 gradients, 195.5 GFLOPs\n",
      "(631, 56877241, 0, 195.46199040000002)\n",
      "Model pruned.\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "pruned_torch_model=prune_model(torch_model, prune_type='structured', dim=1, amount=0.3)\n",
    "print(pruned_torch_model.info())\n",
    "print(\"Model pruned.\")\n",
    "model.model=pruned_torch_model\n",
    "model.save('yolo11x_trained_pruned_local_structured_30_neuron.pt')\n",
    "print(\"Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c9d7856-d13f-4b0f-9c8a-8347a8d0ca20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.58 ðŸš€ Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (NVIDIA A16, 15000MiB)\n",
      "                                                       CUDA:1 (NVIDIA A16, 15000MiB)\n",
      "YOLO11x summary (fused): 464 layers, 56,830,489 parameters, 0 gradients, 194.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jovyan/ML2/datasets/cocoa_diseases/labels/val.cache... 62 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62/62 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:04<00:00,  7.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         62        289          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms preprocess, 62.5ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sparse_model=YOLO('yolo11x_trained_pruned_local_structured_30_neuron.pt')\n",
    "val_sparse= sparse_model.val(\n",
    "    data=\"../datasets/cocoa_diseases/cocoa_dataset.yaml\",\n",
    "    imgsz=640,\n",
    "    batch=2,  # Small batch size\n",
    "    device=[0,1]  # GPU\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
